# -*- coding: utf-8 -*-
"""author_csv_greg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18cm4HYIsp_DBomN_M9T_7kqDTv2IKv7c
"""

import pandas as pd
import numpy as np
import re

from google.colab import drive
drive.mount('/content/drive')

link = "/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/Full_author_name_audrey.csv"
df_author_greg2 = pd.read_csv(link,sep=",")

new = df_author_greg2["Full_author_name"].str.split("/split/", n = 1, expand = True) # les auteurs  et les contacts  sont dans un un nouveau DF

# on stoke author new norm

author_separate2 = pd.concat([df_author_greg2, new], axis=1).reindex(df_author_greg.index)

author_separate2.rename({0 : 'Authors',1 : 'Author_contact'},axis=1,inplace=True) #voir comment on stocke le nouveau DF

print(author_separate.head().to_markdown())

author_separate2.to_csv('/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/author_separate.csv', index=False)

#reste value count et KPI a faire

link2 = "/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/author_separate.csv"
df_author_separate2 = pd.read_csv(link2,sep=",")

print(df_author_separate2)

author_count2=df_author_separate2['Authors'].value_counts()
print(author_count2)

author_separate2.to_csv('/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/author_separate.csv', index=False)
# on ré eneregistre le nouveau CSV authors_separate

author_count2.to_csv('/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/author_count.csv', index=True)
# je teste author count au cas où

#ajouter un df avec dates PMID et titres

link3 = "/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/data/Copie de pubmedArticles.csv"
df_articles = pd.read_csv(link3,sep=",")

print(df_articles.head().to_markdown())

print(df_articles.info())

#avant on supprimer unnammed et PMID de new article pour viter les doublons
df_author_separate2=df_author_separate2.drop(columns=["Unnamed: 0", "PMID"])

#on va ajouter df_articles a author_separate 
new_article2 = pd.concat([df_articles, df_author_separate2], axis=1).reindex(df_author_separate2.index)

print(new_article2.head().to_markdown())

#new_article.Authors.str.split(',').str.len().value_counts()

test = "2015 jun"

print(re.findall('\d{4}',test)[0])

def extract_date(madate):
  try :
    return re.findall('\d{4}',madate)[0]
  except :
    return 'inconnu'


print(extract_date('aaaaaaaaaaaaa'))

print(extract_date(test))



new_article2['Year']= new_article2['Publication_date'].apply(extract_date)

print(new_article2.shape)

print(new_article2.Year.value_counts(normalize = True))

#pk en majorité des inconnu: exploration
df_inconnu = new_article2.loc[new_article2.Year == 'inconnu', ['Year','Publication_date']]

df_inconnu.sort_values('Publication_date',inplace =True)

print(df_inconnu.tail(50).to_markdown())#80 % de mes données j'ai pas de year!!

new_article['Authors']

print(new_article2.head().to_markdown())

#export du 221222
new_article2.to_csv('/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/new_article.csv', index=False)

"""Version 221222 pour avoir les auteurs avec les bonne normes"""

#def clean_auth(auth_name):
#  try :
#    return re.sub(',\s+',' ',auth_name)[0]
#  except :
#    return ' '
# a essayer après correction

#new_article['Authors']= new_article['Authors'].apply(clean_auth)

"""Traitement 151222 New_article changer year en date pour power BI et créer un export CSV pour le power bi

"""

link4 = "/content/drive/MyDrive/2209-Data/Projets/Projet3/ACMG/Greg/new_article.csv"
new_article2 = pd.read_csv(link4,sep=",")

print(new_article2.head().to_markdown())

new_article2=new_article2.drop(columns=["PMID", "PII","DOI","Investigator","Full_author_name","Author_contact"])

print(new_article2.head().to_markdown())

print(new_article2.info())

new_article2.isna().sum()